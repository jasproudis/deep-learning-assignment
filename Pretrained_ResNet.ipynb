{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyO1TcFzvB1d+DqILRJFQyX+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# cnn_model.ipynb\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ypoeNGqzGWm","executionInfo":{"status":"ok","timestamp":1744148024971,"user_tz":-180,"elapsed":34825,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}},"outputId":"810d2905-11e8-4b12-9d1f-d08e747ee164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvJ4AqcJxUYk"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Input, GlobalMaxPooling2D, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","from sklearn.utils.class_weight import compute_sample_weight"]},{"cell_type":"code","source":["# === Config ===\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 32\n","EPOCHS = 20"],"metadata":{"id":"efaf8bSdxc4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Load CSVs ===\n","df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep_Learning/MURA-v1.1/train_image_metadata.csv')\n","df_val = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep_Learning/MURA-v1.1/valid_image_metadata.csv')"],"metadata":{"id":"qOYzrLhsxebP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Image loading and preprocessing ===\n","def load_and_preprocess(path):\n","    img = cv2.imread(path.decode('utf-8'), cv2.IMREAD_GRAYSCALE)\n","    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n","    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","    img = img.astype('float32') / 255.0\n","    return img"],"metadata":{"id":"oLic6GhdyGoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_preprocess(path, label):\n","    img = tf.numpy_function(load_and_preprocess, [path], tf.float32)\n","    img.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n","    return img, label"],"metadata":{"id":"NRnMnTwxyLMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# === tf.data pipeline ===\n","def build_dataset(df, training=True):\n","    paths = df['image_path'].values\n","    labels = df['label'].values.astype(np.int32)\n","    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n","    dataset = dataset.map(tf_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","    if training:\n","        dataset = dataset.shuffle(1000)\n","    return dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"Y8WV7oheyPDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Add sample weights to the dataset ===\n","sample_weights = compute_sample_weight('balanced', df_train['label'].values)\n","train_ds = tf.data.Dataset.from_tensor_slices((df_train['image_path'].values, df_train['label'].values, sample_weights))\n","\n","def tf_preprocess_with_weights(path, label, weight):\n","    img = tf.numpy_function(load_and_preprocess, [path], tf.float32)\n","    img.set_shape((IMAGE_SIZE, IMAGE_SIZE, 3))\n","    return img, label, weight\n","\n","train_ds = train_ds.map(tf_preprocess_with_weights, num_parallel_calls=tf.data.AUTOTUNE)\n","train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","val_ds = build_dataset(df_val, training=False)"],"metadata":{"id":"6Tj5ttRVyR9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Compute sample weights for training ===\n","# sample_weights = compute_sample_weight('balanced', df_train['label'].values)\n"],"metadata":{"id":"PphqxNuXyXeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Model definition ===\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","base_model.trainable = False  # freeze base initially\n","\n","inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","x = base_model(inputs, training=False)\n","x = GlobalMaxPooling2D()(x)\n","x = Dropout(0.3)(x)\n","outputs = Dense(1, activation='sigmoid')(x)\n","\n","model = Model(inputs, outputs)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",")\n"],"metadata":{"id":"skysUk0vyYcg","executionInfo":{"status":"ok","timestamp":1744148042794,"user_tz":-180,"elapsed":7240,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8bfa52b-5277-453a-9ab6-32db35081e19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# === Callbacks ===\n","callbacks = [\n","    EarlyStopping(patience=4, restore_best_weights=True, monitor='val_loss'),\n","    ReduceLROnPlateau(patience=2, factor=0.2, monitor='val_loss')\n","]"],"metadata":{"id":"Y10_3mBayadb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Train ===\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=EPOCHS,\n","    callbacks=callbacks,\n","    verbose=1,\n",")\n"],"metadata":{"id":"l2Hd4fXgyhDq","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"537d8846-abb9-48c9-8dd3-dbd66c0b6bb1","executionInfo":{"status":"error","timestamp":1744172441284,"user_tz":-180,"elapsed":405341,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":12,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m 607/1151\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m42:05\u001b[0m 5s/step - accuracy: 0.8177 - loss: 0.4625 - precision: 0.8233 - recall: 0.8659"]},{"output_type":"error","ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"<ipython-input-5-33ba07433d2a>\", line 4, in load_and_preprocess\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"<ipython-input-5-33ba07433d2a>\", line 4, in load_and_preprocess\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_11985]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-089c6e18b51c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === Train ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"<ipython-input-5-33ba07433d2a>\", line 4, in load_and_preprocess\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) UNKNOWN:  Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"<ipython-input-5-33ba07433d2a>\", line 4, in load_and_preprocess\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_11985]"]}]},{"cell_type":"code","source":["# === Save model ===\n","model.save('resnet_mura_binary.h5')"],"metadata":{"id":"5quSvRzWyj9S","executionInfo":{"status":"aborted","timestamp":1744172441306,"user_tz":-180,"elapsed":3,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate using metrics.py module\n","y_true, y_pred = [], []\n","\n","for batch_x, y_batch in val_ds:\n","    preds = model.predict(batch_x, verbose=0)\n","    y_true.extend(y_batch.numpy().flatten())\n","    y_pred.extend(preds.numpy().flatten())\n","\n","import numpy as np\n","from metrics import get_binary_metrics\n","\n","metrics = get_binary_metrics(np.array(y_true), np.array(y_pred))\n","for k, v in metrics.items():\n","    print(f\"{k}: {v:.4f}\")\n"],"metadata":{"id":"UysQNjT9B2TI","executionInfo":{"status":"aborted","timestamp":1744172441329,"user_tz":-180,"elapsed":2,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training curves\n","import matplotlib.pyplot as plt\n","\n","def plot_history(history):\n","    plt.figure(figsize=(12, 5))\n","\n","    # Accuracy\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['accuracy'], label='Train Acc')\n","    plt.plot(history.history['val_accuracy'], label='Val Acc')\n","    plt.title(\"Accuracy\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend()\n","\n","    # Loss\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Val Loss')\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"OQMqKKSBB7Np","executionInfo":{"status":"aborted","timestamp":1744172441413,"user_tz":-180,"elapsed":58,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_history(history)\n"],"metadata":{"id":"JromI4D6CR01","executionInfo":{"status":"aborted","timestamp":1744172441443,"user_tz":-180,"elapsed":2,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Save model ===\n","model.save('resnet_mura_binary.h5')"],"metadata":{"id":"q9yoMQjhJVDv","executionInfo":{"status":"aborted","timestamp":1744172441463,"user_tz":-180,"elapsed":1,"user":{"displayName":"Jason Christopher","userId":"04389609031786366690"}}},"execution_count":null,"outputs":[]}]}